{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project : Develop model to detect deepfake video with Highest accuracy (possible by us) which has explainability . Will try to create few model to generate comparisons for comparison and then picking one final one as our \"final model\".\n",
    "\n",
    "Business Value: Flagging misinformation/ protecting digital identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3822538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Deep Fake Detection Project\n",
    "# ## Complete Pipeline: Data Analysis → Feature Engineering → Model Training → Hyperparameter Tuning\n",
    "#\n",
    "# **Dataset**: [Hemgg/deep-fake-detection-dfd-entire-original-dataset](https://huggingface.co/datasets/Hemgg/deep-fake-detection-dfd-entire-original-dataset)\n",
    "#\n",
    "# **Objective**: Detect original vs AI-generated images and videos\n",
    "#\n",
    "# **Approach**:\n",
    "# - Comprehensive EDA\n",
    "# - Feature engineering (spatial, frequency, texture features)\n",
    "# - Multiple CNN architectures + Transfer Learning\n",
    "# - Hyperparameter optimization\n",
    "# - Model evaluation and comparison\n",
    "#\n",
    "%pip install optuna\n",
    "%pip install torchcodec\n",
    "# %%\n",
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "import timm\n",
    "import torchcodec\n",
    "\n",
    "# Computer Vision\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage import feature, filters\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "# ML & Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report,\n",
    "    roc_curve, auc, roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# HuggingFace\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "\n",
    "# Utilities\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"Using CPU - training will be slower\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b95544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2. Data Loading and Label Analysis\n",
    "# Set your Hugging Face token (if needed)\n",
    "# os.environ[\"HF_TOKEN\"] = \"your_token_here\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING DATASET FROM HUGGINGFACE (200 RECORDS ONLY)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "MAX_RECORDS = 200  # Only download first 200 records\n",
    "\n",
    "# Configure video decoding to use av (PyAV) instead of torchcodec\n",
    "os.environ['HF_DATASETS_VIDEO_DECODER'] = 'av'  # Using PyAV instead of torchcodec\n",
    "\n",
    "def infer_label_from_path(video_path):\n",
    "    \"\"\"Extract label from HF dataset path structure\"\"\"\n",
    "    path_str = str(video_path).lower()\n",
    "    if 'original_sequences' in path_str or 'pristine' in path_str or 'original' in path_str:\n",
    "        return 0  # Real/Original\n",
    "    elif 'manipulated_sequences' in path_str or 'dfdc' in path_str or 'fake' in path_str or 'deepfake' in path_str:\n",
    "        return 1  # Fake/Manipulated\n",
    "    else:\n",
    "        # Default based on dataset name - this dataset might be all original\n",
    "        return 0  # Default to original for safety\n",
    "\n",
    "try:\n",
    "    # Load dataset in streaming mode\n",
    "    print(f\"[INFO] Loading first {MAX_RECORDS} records...\")\n",
    "    dataset_stream = load_dataset(\n",
    "        \"Hemgg/deep-fake-detection-dfd-entire-original-dataset\",\n",
    "        streaming=True,\n",
    "        split=\"train\"\n",
    "    )\n",
    "    \n",
    "    # Extract first 200 records and analyze labels\n",
    "    train_data_list = []\n",
    "    label_analysis = []\n",
    "    \n",
    "    for i, sample in enumerate(tqdm(dataset_stream, desc=\"Loading samples\", total=MAX_RECORDS)):\n",
    "        if i >= MAX_RECORDS:\n",
    "            break\n",
    "        \n",
    "        # Get video path\n",
    "        video_path = sample.get('video', {}).get('path', '')\n",
    "        if isinstance(video_path, dict):\n",
    "            video_path = video_path.get('path', '')\n",
    "        \n",
    "        # Infer label from path\n",
    "        label = infer_label_from_path(video_path)\n",
    "        \n",
    "        label_analysis.append({\n",
    "            'index': i,\n",
    "            'path': str(video_path),\n",
    "            'label': label,\n",
    "            'label_name': 'Original' if label == 0 else 'Manipulated'\n",
    "        })\n",
    "        \n",
    "        train_data_list.append(sample)\n",
    "    \n",
    "    # Convert to DataFrame for analysis\n",
    "    label_df = pd.DataFrame(label_analysis)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LABEL DISTRIBUTION ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nTotal samples analyzed: {len(label_df)}\")\n",
    "    print(f\"\\nLabel Distribution:\")\n",
    "    print(label_df['label_name'].value_counts())\n",
    "    print(f\"\\nLabel Percentages:\")\n",
    "    print(label_df['label_name'].value_counts(normalize=True) * 100)\n",
    "    \n",
    "    # Check if we have both classes\n",
    "    unique_labels = label_df['label'].unique()\n",
    "    print(f\"\\nUnique labels found: {unique_labels}\")\n",
    "    \n",
    "    if len(unique_labels) == 1:\n",
    "        print(\"\\n⚠️  WARNING: Only one class found in the dataset!\")\n",
    "        print(f\"   All samples are labeled as: {'Original' if unique_labels[0] == 0 else 'Manipulated'}\")\n",
    "        print(\"\\n   This dataset might contain only original videos.\")\n",
    "        print(\"   You may need to:\")\n",
    "        print(\"   1. Use a different dataset that has both classes\")\n",
    "        print(\"   2. Combine with another dataset that has manipulated videos\")\n",
    "        print(\"   3. Check if labels are stored differently in the dataset\")\n",
    "    else:\n",
    "        print(\"\\n✓ Both classes found in the dataset!\")\n",
    "        print(\"   The dataset contains both Original and Manipulated videos.\")\n",
    "    \n",
    "    # Show sample paths\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SAMPLE PATHS (First 10):\")\n",
    "    print(\"=\"*80)\n",
    "    for idx, row in label_df.head(10).iterrows():\n",
    "        print(f\"Sample {row['index']}: {row['label_name']}\")\n",
    "        print(f\"  Path: {row['path'][:100]}...\")\n",
    "    \n",
    "    # Visualize label distribution\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Count plot\n",
    "    label_counts = label_df['label_name'].value_counts()\n",
    "    axes[0].bar(label_counts.index, label_counts.values, color=['#2ecc71', '#e74c3c'])\n",
    "    axes[0].set_title('Label Distribution (Count)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Label', fontsize=12)\n",
    "    axes[0].set_ylabel('Count', fontsize=12)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Pie chart\n",
    "    colors = ['#2ecc71', '#e74c3c']\n",
    "    axes[1].pie(label_counts.values, labels=label_counts.index, autopct='%1.1f%%',\n",
    "               colors=colors[:len(label_counts)], startangle=90)\n",
    "    axes[1].set_title('Label Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('label_distribution_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Convert to Dataset object\n",
    "    from datasets import Dataset\n",
    "    train_data = Dataset.from_list(train_data_list)\n",
    "    print(f\"\\n✓ Dataset loaded: {len(train_data)} records\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Error loading dataset: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5d824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional analysis: Check dataset structure more deeply\n",
    "print(\"=\"*80)\n",
    "print(\"DEEP DATASET STRUCTURE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check what information is available in each sample\n",
    "if 'train_data' in locals() and len(train_data) > 0:\n",
    "    sample = train_data[0]\n",
    "    print(\"\\nSample structure:\")\n",
    "    print(f\"Keys: {sample.keys()}\")\n",
    "    print(f\"\\nVideo data type: {type(sample.get('video', {}))}\")\n",
    "    \n",
    "    if 'video' in sample:\n",
    "        video_data = sample['video']\n",
    "        if isinstance(video_data, dict):\n",
    "            print(f\"Video dict keys: {video_data.keys()}\")\n",
    "            if 'path' in video_data:\n",
    "                print(f\"Video path: {video_data['path']}\")\n",
    "    \n",
    "    # Check if there are any other fields that might contain labels\n",
    "    print(\"\\nChecking for label fields in dataset...\")\n",
    "    all_keys = set()\n",
    "    for i in range(min(10, len(train_data))):\n",
    "        sample = train_data[i]\n",
    "        all_keys.update(sample.keys())\n",
    "    \n",
    "    print(f\"All available keys in samples: {all_keys}\")\n",
    "    \n",
    "    # Check if dataset has features/columns with label information\n",
    "    if hasattr(train_data, 'features'):\n",
    "        print(f\"\\nDataset features: {train_data.features}\")\n",
    "    \n",
    "    if hasattr(train_data, 'column_names'):\n",
    "        print(f\"Dataset column names: {train_data.column_names}\")\n",
    "else:\n",
    "    print(\"Dataset not loaded. Please run the previous cell first.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
