{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project : Develop model to detect deepfake video with Highest accuracy (possible by us) which has explainability . Will try to create few model to generate comparisons for comparison and then picking one final one as our \"final model\".\n",
    "\n",
    "Business Value: Flagging misinformation/ protecting digital identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3822538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Deep Fake Detection Project\n",
    "# ## Complete Pipeline: Data Analysis ‚Üí Feature Engineering ‚Üí Model Training ‚Üí Hyperparameter Tuning\n",
    "#\n",
    "# **Dataset**: Google Drive - Celeb-Real, Celeb-Fake, and Testing folders\n",
    "# - **Celeb-Real**: Real/Original videos (Label: 0, \"Celeb-Real\")\n",
    "# - **Celeb-Fake**: Fake/Manipulated videos (Label: 1, \"Fake\")\n",
    "# - **Testing**: Test videos for evaluation\n",
    "#\n",
    "# **Dataset Link**: https://drive.google.com/drive/folders/1nBKjUpi2wQyMfWDuNsreqY11DVZrbk7x\n",
    "#\n",
    "# **Objective**: Detect original vs AI-generated images and videos\n",
    "#\n",
    "# **Approach**:\n",
    "# - Comprehensive EDA\n",
    "# - Feature engineering (spatial, frequency, texture features)\n",
    "# - Multiple CNN architectures + Transfer Learning\n",
    "# - Hyperparameter optimization\n",
    "# - Model evaluation and comparison\n",
    "#\n",
    "%pip install optuna\n",
    "%pip install torchcodec\n",
    "%pip install gdown\n",
    "# %%\n",
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "import timm\n",
    "import torchcodec\n",
    "\n",
    "# Computer Vision\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage import feature, filters\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "# ML & Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report,\n",
    "    roc_curve, auc, roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# HuggingFace\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "\n",
    "# Utilities\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"Using CPU - training will be slower\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b95544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2. Data Loading from Google Drive Folders\n",
    "# Dataset Structure:\n",
    "# - celeb-real/: Real videos (label: 0, \"Celeb-Real\")\n",
    "# - celeb-fake/: Fake videos (label: 1, \"Fake\")\n",
    "# - testing/: Test videos (for evaluation)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING DATASET FROM GOOGLE DRIVE FOLDERS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Install gdown for downloading from Google Drive\n",
    "%pip install gdown\n",
    "\n",
    "import gdown\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# Set up data directory\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Google Drive folder IDs (extracted from the share link)\n",
    "GOOGLE_DRIVE_FOLDER_ID = \"1nBKjUpi2wQyMfWDuNsreqY11DVZrbk7x\"\n",
    "CELEB_REAL_FOLDER = DATA_DIR / \"Celeb-Real\"\n",
    "CELEB_FAKE_FOLDER = DATA_DIR / \"Celeb-Fake\"\n",
    "TESTING_FOLDER = DATA_DIR / \"Testing\"\n",
    "\n",
    "def download_from_google_drive(folder_id, output_dir):\n",
    "    \"\"\"Download folder from Google Drive using gdown\"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(f\"Downloading from Google Drive folder: {folder_id}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    \n",
    "    # Download folder as zip\n",
    "    url = f\"https://drive.google.com/uc?id={folder_id}\"\n",
    "    zip_path = output_dir / \"dataset.zip\"\n",
    "    \n",
    "    try:\n",
    "        gdown.download_folder(url, output=str(output_dir), quiet=False, use_cookies=False)\n",
    "        print(f\"‚úÖ Downloaded to {output_dir}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Download error: {e}\")\n",
    "        print(\"Please download manually from:\")\n",
    "        print(f\"https://drive.google.com/drive/folders/{folder_id}\")\n",
    "        print(f\"Extract to: {output_dir}\")\n",
    "        return False\n",
    "\n",
    "def load_videos_from_folder(folder_path, label, label_name):\n",
    "    \"\"\"Load all video files from a folder\"\"\"\n",
    "    folder_path = Path(folder_path)\n",
    "    if not folder_path.exists():\n",
    "        return []\n",
    "    \n",
    "    # Supported video formats\n",
    "    video_extensions = ['*.mp4', '*.avi', '*.mov', '*.mkv', '*.flv', '*.wmv', '*.webm']\n",
    "    video_files = []\n",
    "    \n",
    "    for ext in video_extensions:\n",
    "        video_files.extend(glob.glob(str(folder_path / \"**\" / ext), recursive=True))\n",
    "    \n",
    "    # Create data entries\n",
    "    data_list = []\n",
    "    for video_path in video_files:\n",
    "        data_list.append({\n",
    "            'video_path': video_path,\n",
    "            'label': label,\n",
    "            'label_name': label_name,\n",
    "            'folder': folder_path.name\n",
    "        })\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "# Download or check for local dataset\n",
    "print(\"\\n[INFO] Checking for dataset folders...\")\n",
    "print(f\"Celeb-Real folder: {CELEB_REAL_FOLDER}\")\n",
    "print(f\"Celeb-Fake folder: {CELEB_FAKE_FOLDER}\")\n",
    "print(f\"Testing folder: {TESTING_FOLDER}\")\n",
    "\n",
    "# Check if folders exist locally\n",
    "if not (CELEB_REAL_FOLDER.exists() and CELEB_FAKE_FOLDER.exists()):\n",
    "    print(\"\\n[INFO] Dataset folders not found locally.\")\n",
    "    print(\"Attempting to download from Google Drive...\")\n",
    "    print(\"Note: If download fails, please download manually and place folders in 'data/' directory\")\n",
    "    \n",
    "    # Try to download (this might not work for large folders, manual download recommended)\n",
    "    download_success = download_from_google_drive(GOOGLE_DRIVE_FOLDER_ID, DATA_DIR)\n",
    "    \n",
    "    if not download_success:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"MANUAL DOWNLOAD REQUIRED\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"Please follow these steps:\")\n",
    "        print(f\"1. Open: https://drive.google.com/drive/folders/{GOOGLE_DRIVE_FOLDER_ID}\")\n",
    "        print(\"2. Download the three folders: Celeb-Real, Celeb-Fake, Testing\")\n",
    "        print(f\"3. Extract them to: {DATA_DIR.absolute()}\")\n",
    "        print(\"4. Ensure folder structure:\")\n",
    "        print(f\"   {DATA_DIR}/Celeb-Real/\")\n",
    "        print(f\"   {DATA_DIR}/Celeb-Fake/\")\n",
    "        print(f\"   {DATA_DIR}/Testing/\")\n",
    "        print(\"\\nThen re-run this cell.\")\n",
    "else:\n",
    "    print(\"‚úÖ Dataset folders found locally!\")\n",
    "\n",
    "# Load videos from folders\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING VIDEOS FROM FOLDERS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load training data (Celeb-Real and Celeb-Fake)\n",
    "train_data_list = []\n",
    "train_data_list.extend(load_videos_from_folder(CELEB_REAL_FOLDER, label=0, label_name=\"Celeb-Real\"))\n",
    "train_data_list.extend(load_videos_from_folder(CELEB_FAKE_FOLDER, label=1, label_name=\"Fake\"))\n",
    "\n",
    "# Load test data (Testing folder)\n",
    "test_data_list = load_videos_from_folder(TESTING_FOLDER, label=None, label_name=\"Testing\")\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "train_df = pd.DataFrame(train_data_list)\n",
    "test_df = pd.DataFrame(test_data_list)\n",
    "\n",
    "print(f\"\\n‚úÖ Training videos loaded: {len(train_df)}\")\n",
    "print(f\"‚úÖ Test videos loaded: {len(test_df)}\")\n",
    "\n",
    "if len(train_df) > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LABEL DISTRIBUTION ANALYSIS (Training Data)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nTotal training samples: {len(train_df)}\")\n",
    "    print(f\"\\nLabel Distribution:\")\n",
    "    print(train_df['label_name'].value_counts())\n",
    "    print(f\"\\nLabel Percentages:\")\n",
    "    print(train_df['label_name'].value_counts(normalize=True) * 100)\n",
    "    \n",
    "    # Check if we have both classes\n",
    "    unique_labels = train_df['label'].unique()\n",
    "    print(f\"\\nUnique labels found: {unique_labels}\")\n",
    "    \n",
    "    if len(unique_labels) == 1:\n",
    "        print(\"\\n‚ö†Ô∏è  WARNING: Only one class found in the dataset!\")\n",
    "        print(f\"   All samples are labeled as: {train_df['label_name'].iloc[0]}\")\n",
    "    else:\n",
    "        print(\"\\n‚úì Both classes found in the dataset!\")\n",
    "        print(\"   The dataset contains both Celeb-Real and Fake videos.\")\n",
    "    \n",
    "    # Show sample paths\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SAMPLE PATHS (First 10):\")\n",
    "    print(\"=\"*80)\n",
    "    for idx, row in train_df.head(10).iterrows():\n",
    "        print(f\"Sample {idx}: {row['label_name']}\")\n",
    "        print(f\"  Path: {row['video_path']}\")\n",
    "    \n",
    "    # Visualize label distribution\n",
    "    if len(train_df) > 0:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Count plot\n",
    "        label_counts = train_df['label_name'].value_counts()\n",
    "        axes[0].bar(label_counts.index, label_counts.values, color=['#2ecc71', '#e74c3c'])\n",
    "        axes[0].set_title('Label Distribution (Count)', fontsize=14, fontweight='bold')\n",
    "        axes[0].set_xlabel('Label', fontsize=12)\n",
    "        axes[0].set_ylabel('Count', fontsize=12)\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Pie chart\n",
    "        colors = ['#2ecc71', '#e74c3c']\n",
    "        axes[1].pie(label_counts.values, labels=label_counts.index, autopct='%1.1f%%',\n",
    "                   colors=colors[:len(label_counts)], startangle=90)\n",
    "        axes[1].set_title('Label Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('label_distribution_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    print(f\"\\n‚úì Training dataset loaded: {len(train_df)} videos\")\n",
    "    print(f\"‚úì Test dataset loaded: {len(test_df)} videos\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No training videos found!\")\n",
    "    print(\"Please ensure the dataset folders are downloaded and placed in the 'data/' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5d824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional analysis: Check dataset structure and video files\n",
    "print(\"=\"*80)\n",
    "print(\"DATASET STRUCTURE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'train_df' in locals() and len(train_df) > 0:\n",
    "    print(f\"\\n‚úÖ Training Dataset Structure:\")\n",
    "    print(f\"   Total videos: {len(train_df)}\")\n",
    "    print(f\"   Columns: {train_df.columns.tolist()}\")\n",
    "    print(f\"\\n   Label distribution:\")\n",
    "    print(train_df['label_name'].value_counts())\n",
    "    \n",
    "    # Check video file formats\n",
    "    print(f\"\\nüìπ Video File Formats:\")\n",
    "    train_df['extension'] = train_df['video_path'].apply(lambda x: Path(x).suffix.lower())\n",
    "    print(train_df['extension'].value_counts())\n",
    "    \n",
    "    # Sample video paths by label\n",
    "    print(f\"\\nüìÅ Sample Video Paths by Label:\")\n",
    "    for label_name in train_df['label_name'].unique():\n",
    "        print(f\"\\n   {label_name} videos:\")\n",
    "        sample_paths = train_df[train_df['label_name'] == label_name]['video_path'].head(3)\n",
    "        for path in sample_paths:\n",
    "            print(f\"     - {Path(path).name}\")\n",
    "    \n",
    "    if 'test_df' in locals() and len(test_df) > 0:\n",
    "        print(f\"\\n‚úÖ Test Dataset Structure:\")\n",
    "        print(f\"   Total test videos: {len(test_df)}\")\n",
    "        print(f\"   Test videos are in: {TESTING_FOLDER}\")\n",
    "    \n",
    "    print(f\"\\nüìä Dataset Summary:\")\n",
    "    print(f\"   Training: {len(train_df)} videos\")\n",
    "    print(f\"   Testing: {len(test_df) if 'test_df' in locals() else 0} videos\")\n",
    "    print(f\"   Total: {len(train_df) + (len(test_df) if 'test_df' in locals() else 0)} videos\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Dataset not loaded. Please run the previous cell first.\")\n",
    "    print(\"Make sure the dataset folders are downloaded and placed in the 'data/' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c12ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract frame from video file\n",
    "def extract_frame_from_video(video_path, frame_idx=0):\n",
    "    \"\"\"Extract a frame from video file path\"\"\"\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(str(video_path))\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video {video_path}\")\n",
    "            return None\n",
    "        \n",
    "        # Get total frames\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # Set frame position\n",
    "        if frame_idx >= total_frames:\n",
    "            frame_idx = total_frames - 1\n",
    "        \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        cap.release()\n",
    "        \n",
    "        if ret:\n",
    "            # Convert BGR to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            return frame_rgb\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting frame from {video_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test video loading\n",
    "if 'train_df' in locals() and len(train_df) > 0:\n",
    "    print(\"Testing video frame extraction...\")\n",
    "    sample_video = train_df.iloc[0]['video_path']\n",
    "    print(f\"Sample video: {sample_video}\")\n",
    "    \n",
    "    frame = extract_frame_from_video(sample_video, frame_idx=0)\n",
    "    if frame is not None:\n",
    "        print(f\"‚úÖ Frame extracted successfully!\")\n",
    "        print(f\"   Frame shape: {frame.shape}\")\n",
    "        \n",
    "        # Display sample frame\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(frame)\n",
    "        plt.title(f\"Sample Frame from: {Path(sample_video).name}\\nLabel: {train_df.iloc[0]['label_name']}\")\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('sample_video_frame.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Could not extract frame. Check video file format.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No training data available. Please load dataset first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f9e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset Class for Video Loading\n",
    "class VideoDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for loading videos from local folders.\n",
    "    Labels are assigned based on folder location:\n",
    "    - Celeb-Real folder ‚Üí Label 0 (\"Celeb-Real\")\n",
    "    - Celeb-Fake folder ‚Üí Label 1 (\"Fake\")\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, transform=None, num_frames=16, frame_interval=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe: DataFrame with columns ['video_path', 'label', 'label_name', 'folder']\n",
    "            transform: Optional transform to be applied on frames\n",
    "            num_frames: Number of frames to extract from each video\n",
    "            frame_interval: Interval between frames (1 = consecutive frames)\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.num_frames = num_frames\n",
    "        self.frame_interval = frame_interval\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.dataframe.iloc[idx]['video_path']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "        label_name = self.dataframe.iloc[idx]['label_name']\n",
    "        folder = self.dataframe.iloc[idx]['folder']\n",
    "        \n",
    "        # Extract frames from video\n",
    "        frames = self.extract_frames(video_path)\n",
    "        \n",
    "        # Apply transforms if provided\n",
    "        if self.transform:\n",
    "            frames = [self.transform(frame) for frame in frames]\n",
    "        \n",
    "        # Convert list of frames to tensor\n",
    "        # Stack frames: [num_frames, C, H, W]\n",
    "        frames_tensor = torch.stack(frames)\n",
    "        \n",
    "        return {\n",
    "            'frames': frames_tensor,\n",
    "            'label': torch.tensor(label, dtype=torch.long),\n",
    "            'label_name': label_name,\n",
    "            'folder': folder,\n",
    "            'video_path': video_path\n",
    "        }\n",
    "    \n",
    "    def extract_frames(self, video_path):\n",
    "        \"\"\"Extract frames from video file\"\"\"\n",
    "        cap = cv2.VideoCapture(str(video_path))\n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(f\"Could not open video: {video_path}\")\n",
    "        \n",
    "        frames = []\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        # Calculate frame indices to extract\n",
    "        if total_frames < self.num_frames * self.frame_interval:\n",
    "            # If video is shorter, extract all frames and pad\n",
    "            frame_indices = list(range(0, total_frames, self.frame_interval))\n",
    "        else:\n",
    "            # Extract evenly spaced frames\n",
    "            step = max(1, total_frames // (self.num_frames * self.frame_interval))\n",
    "            frame_indices = [i * step for i in range(self.num_frames)]\n",
    "        \n",
    "        for frame_idx in frame_indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                # Convert BGR to RGB\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                # Convert to PIL Image for transforms\n",
    "                frame_pil = Image.fromarray(frame_rgb)\n",
    "                frames.append(frame_pil)\n",
    "            else:\n",
    "                # If frame read fails, use last successful frame\n",
    "                if frames:\n",
    "                    frames.append(frames[-1])\n",
    "                else:\n",
    "                    # Create black frame as fallback\n",
    "                    frame_pil = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "                    frames.append(frame_pil)\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        # Pad or trim to exact number of frames\n",
    "        while len(frames) < self.num_frames:\n",
    "            frames.append(frames[-1] if frames else Image.new('RGB', (224, 224), (0, 0, 0)))\n",
    "        \n",
    "        frames = frames[:self.num_frames]\n",
    "        \n",
    "        return frames\n",
    "\n",
    "# Define transforms for training and validation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets if training data is available\n",
    "if 'train_df' in locals() and len(train_df) > 0:\n",
    "    print(\"Creating PyTorch datasets...\")\n",
    "    \n",
    "    # Split training data into train and validation sets\n",
    "    train_split_df, val_split_df = train_test_split(\n",
    "        train_df, \n",
    "        test_size=0.2, \n",
    "        random_state=SEED, \n",
    "        stratify=train_df['label']\n",
    "    )\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = VideoDataset(train_split_df, transform=train_transform, num_frames=16)\n",
    "    val_dataset = VideoDataset(val_split_df, transform=val_transform, num_frames=16)\n",
    "    \n",
    "    # Create test dataset if available\n",
    "    if 'test_df' in locals() and len(test_df) > 0:\n",
    "        test_dataset = VideoDataset(test_df, transform=val_transform, num_frames=16)\n",
    "        print(f\"‚úÖ Test dataset created: {len(test_dataset)} videos\")\n",
    "    else:\n",
    "        test_dataset = None\n",
    "        print(\"‚ö†Ô∏è  No test dataset available\")\n",
    "    \n",
    "    print(f\"‚úÖ Training dataset: {len(train_dataset)} videos\")\n",
    "    print(f\"‚úÖ Validation dataset: {len(val_dataset)} videos\")\n",
    "    print(f\"\\nDataset splits:\")\n",
    "    print(f\"  Train: {len(train_split_df)} videos\")\n",
    "    print(f\"  Validation: {len(val_split_df)} videos\")\n",
    "    print(f\"  Test: {len(test_df) if 'test_df' in locals() else 0} videos\")\n",
    "    \n",
    "    # Test dataset loading\n",
    "    print(\"\\nTesting dataset loading...\")\n",
    "    sample = train_dataset[0]\n",
    "    print(f\"‚úÖ Sample loaded successfully!\")\n",
    "    print(f\"   Frames shape: {sample['frames'].shape}\")\n",
    "    print(f\"   Label: {sample['label'].item()} ({sample['label_name']})\")\n",
    "    print(f\"   Folder: {sample['folder']}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No training data available. Please load dataset first (run Cell 2).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
