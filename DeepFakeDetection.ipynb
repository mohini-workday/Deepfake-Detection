{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project : Develop model to detect deepfake video with Highest accuracy (possible by us) which has explainability . Will try to create few model to generate comparisons for comparison and then picking one final one as our \"final model\".\n",
    "\n",
    "Business Value: Flagging misinformation/ protecting digital identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3822538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in ./deepfake_env/lib/python3.14/site-packages (4.6.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in ./deepfake_env/lib/python3.14/site-packages (from optuna) (1.17.2)\n",
      "Requirement already satisfied: colorlog in ./deepfake_env/lib/python3.14/site-packages (from optuna) (6.10.1)\n",
      "Requirement already satisfied: numpy in ./deepfake_env/lib/python3.14/site-packages (from optuna) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./deepfake_env/lib/python3.14/site-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in ./deepfake_env/lib/python3.14/site-packages (from optuna) (2.0.44)\n",
      "Requirement already satisfied: tqdm in ./deepfake_env/lib/python3.14/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in ./deepfake_env/lib/python3.14/site-packages (from optuna) (6.0.3)\n",
      "Requirement already satisfied: Mako in ./deepfake_env/lib/python3.14/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in ./deepfake_env/lib/python3.14/site-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in ./deepfake_env/lib/python3.14/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: gdown in ./deepfake_env/lib/python3.14/site-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in ./deepfake_env/lib/python3.14/site-packages (from gdown) (4.14.3)\n",
      "Requirement already satisfied: filelock in ./deepfake_env/lib/python3.14/site-packages (from gdown) (3.20.0)\n",
      "Requirement already satisfied: requests[socks] in ./deepfake_env/lib/python3.14/site-packages (from gdown) (2.32.5)\n",
      "Requirement already satisfied: tqdm in ./deepfake_env/lib/python3.14/site-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in ./deepfake_env/lib/python3.14/site-packages (from beautifulsoup4->gdown) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./deepfake_env/lib/python3.14/site-packages (from beautifulsoup4->gdown) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./deepfake_env/lib/python3.14/site-packages (from requests[socks]->gdown) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./deepfake_env/lib/python3.14/site-packages (from requests[socks]->gdown) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./deepfake_env/lib/python3.14/site-packages (from requests[socks]->gdown) (2.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./deepfake_env/lib/python3.14/site-packages (from requests[socks]->gdown) (2025.11.12)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in ./deepfake_env/lib/python3.14/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Using device: cpu\n",
      "Using CPU - training will be slower\n"
     ]
    }
   ],
   "source": [
    "# # Deep Fake Detection Project\n",
    "# ## Complete Pipeline: Data Analysis ‚Üí Feature Engineering ‚Üí Model Training ‚Üí Hyperparameter Tuning\n",
    "#\n",
    "# **Dataset**: Google Drive - Celeb-Real, Celeb-Fake, and Testing folders\n",
    "# - **Celeb-Real**: Real/Original videos (Label: 0, \"Celeb-Real\")\n",
    "# - **Celeb-Fake**: Fake/Manipulated videos (Label: 1, \"Fake\")\n",
    "# - **Testing**: Test videos for evaluation\n",
    "#\n",
    "# **Dataset Link**: https://drive.google.com/drive/folders/1nBKjUpi2wQyMfWDuNsreqY11DVZrbk7x\n",
    "#\n",
    "# **Objective**: Detect original vs AI-generated images and videos\n",
    "#\n",
    "# **Approach**:\n",
    "# - Comprehensive EDA\n",
    "# - Feature engineering (spatial, frequency, texture features)\n",
    "# - Multiple CNN architectures + Transfer Learning\n",
    "# - Hyperparameter optimization\n",
    "# - Model evaluation and comparison\n",
    "#\n",
    "%pip install optuna\n",
    "%pip install gdown\n",
    "# Note: torchcodec is not needed - we use OpenCV for video processing\n",
    "# %%\n",
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "import timm\n",
    "# torchcodec not needed - using OpenCV for video processing instead\n",
    "# import torchcodec  # Optional: requires FFmpeg installation\n",
    "\n",
    "# Computer Vision\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage import feature, filters\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "# ML & Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report,\n",
    "    roc_curve, auc, roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# HuggingFace\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "\n",
    "# Utilities\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"Using CPU - training will be slower\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b95544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING DATASET FROM GOOGLE DRIVE FOLDERS\n",
      "================================================================================\n",
      "Requirement already satisfied: gdown in ./deepfake_env/lib/python3.14/site-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in ./deepfake_env/lib/python3.14/site-packages (from gdown) (4.14.3)\n",
      "Requirement already satisfied: filelock in ./deepfake_env/lib/python3.14/site-packages (from gdown) (3.20.0)\n",
      "Requirement already satisfied: requests[socks] in ./deepfake_env/lib/python3.14/site-packages (from gdown) (2.32.5)\n",
      "Requirement already satisfied: tqdm in ./deepfake_env/lib/python3.14/site-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in ./deepfake_env/lib/python3.14/site-packages (from beautifulsoup4->gdown) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./deepfake_env/lib/python3.14/site-packages (from beautifulsoup4->gdown) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./deepfake_env/lib/python3.14/site-packages (from requests[socks]->gdown) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./deepfake_env/lib/python3.14/site-packages (from requests[socks]->gdown) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./deepfake_env/lib/python3.14/site-packages (from requests[socks]->gdown) (2.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./deepfake_env/lib/python3.14/site-packages (from requests[socks]->gdown) (2025.11.12)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in ./deepfake_env/lib/python3.14/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "[INFO] Checking for dataset folders...\n",
      "Celeb-Real folder: data/Celeb-Real\n",
      "Celeb-Fake folder: data/Celeb-Fake\n",
      "Testing folder: data/Testing\n",
      "\n",
      "[INFO] Dataset folders not found locally.\n",
      "Attempting to download from Google Drive...\n",
      "Note: If download fails, please download manually and place folders in 'data/' directory\n",
      "Downloading from Google Drive folder: 1nBKjUpi2wQyMfWDuNsreqY11DVZrbk7x\n",
      "Output directory: data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving folder 18qhZEXhRWb0NmUHoYQyADJvai9sS3xTi Celeb-Fake\n",
      "Processing file 1-oESGLoEYUhsqerwvocu3o4eE2WK0PjQ id2_id0_0000.mp4\n",
      "Processing file 1BPgDGKNxhsvNM26yThzdbJnBMP0lWi8M id2_id0_0003.mp4\n",
      "Processing file 1t5QnYJ7HXTaYv_gvNFu1RFlOclrVVDr4 id2_id0_0004.mp4\n",
      "Processing file 1Oz8qm_50xnGfO8F0VLoBoOTt0WinOKP0 id2_id3_0003.mp4\n",
      "Processing file 1g0KCsT11YKvGbAJGdWHHFlQc9qWdVNEb id2_id3_0007.mp4\n",
      "Processing file 1h2q59nSIHypEIxDnTlA6Iui0gDbtS6id id2_id4_0009.mp4\n",
      "Processing file 16NNAKxLpviTm8zMRo-KaL6Dxvpr6loUG id2_id6_0008.mp4\n",
      "Processing file 1rGcakJoSKJT_CfC5tT9GQ8vzdC4XkBjO id2_id9_0005.mp4\n",
      "Processing file 1_C5BJHbh-Dz3XlPGArYA5ZgCHCnUMfOE id2_id16_0001.mp4\n",
      "Processing file 1J6XN307RMtUGsQqgUfXflWib4eyJ9ghD id2_id17_0000.mp4\n",
      "Processing file 1-9Gq18b5mMZ5ei_biBeoW-qZ-PxeviWa id2_id17_0005.mp4\n",
      "Processing file 1a3ObMXQpTadQta9JtnfYd0KvcTbFJ_XC id2_id20_0004.mp4\n",
      "Processing file 1uXUGKYwCRPp9cXlZBqMqUxvFf8veKetk id2_id21_0001.mp4\n",
      "Processing file 14s1g3gTtKw3ibsNor230xvlF8QvOS03P id2_id23_0000.mp4\n",
      "Processing file 1g_D-TUif8nDPfLRWrSvzwOXNnEETYVWU id2_id23_0005.mp4\n",
      "Processing file 1vTgrw5QL4FeChQSfETqgqwugXDV0eb4P id2_id26_0009.mp4\n",
      "Processing file 1U_3Li9N5MV7_aPZnVVvJ13EfgGG-Jqsw id2_id30_0003.mp4\n",
      "Processing file 1yp6g6NBo3oD8AXvhikj-PlC672yfZnnc id2_id31_0002.mp4\n",
      "Processing file 1LAIY9xpGly34p2F4EDwmk1bGhqkUFiHC id2_id31_0003.mp4\n",
      "Processing file 1MmIEanHMmjaohydXh4snk_sWNQ9BSG7L id2_id35_0000.mp4\n",
      "Processing file 1Mr42F3wdhtMkCBChE5GzJmQ3LZMwyrKk id2_id35_0004.mp4\n",
      "Processing file 13MfiWYsJTZRkTyzZQqQrQlAQGChGrZIV id2_id35_0007.mp4\n",
      "Processing file 1NQrKaLP6JNPdQV7dwSE7O9g02GpshTmU id2_id37_0002.mp4\n",
      "Processing file 1c0LmLmvOHHpUhjOlZmEHvNNW8nziuNrh id2_id37_0006.mp4\n",
      "Processing file 1o5Gx7cKNWW7khvBSboTJf-ZYi5LDsxFy id2_id37_0008.mp4\n",
      "Processing file 1bJUaTvyih6sns_5IgnNR7Vi8t0lfDXEu id5_id61_0001.mp4\n",
      "Processing file 1zI4_pBgVqU6Y3zUguQJwX8Ursa39LzZO id6_id0_0007.mp4\n",
      "Processing file 1t1XqsfJf7uWLqoHrrUroZ4NNU_L-shra id6_id1_0007.mp4\n",
      "Processing file 1oX6YZWcbHtOA6cZCmXbwlyVCDEqdkY_z id6_id2_0005.mp4\n",
      "Processing file 1Pid5y8uFEERHk8QAQlEcUKKpCKnlseap id6_id3_0001.mp4\n",
      "Processing file 173KC4zsgnLbBg7gWGP-_7ZMOM9FXKQy1 id6_id3_0003.mp4\n",
      "Processing file 1_3EugPbP8z5yGqyY4f28w7PiPU19fNxo id6_id3_0007.mp4\n",
      "Processing file 1ilAOZAKo-oKKtQIYqpf9yMM_twR2umMF id6_id4_0006.mp4\n",
      "Processing file 1l-zk5488XOnu0IMMxORBBMP74yWVGAiE id6_id4_0007.mp4\n",
      "Processing file 1KqKrK5FgBdvnyAHwRk8kybTcSavXb7VD id6_id4_0008.mp4\n",
      "Processing file 1UDTFbvQpyzz2s9V0KXt52znuP9wl4bGz id6_id4_0009.mp4\n",
      "Processing file 1FDdb_u6AMwsgnhuhseeBGUKw58SLWOX9 id6_id9_0000.mp4\n",
      "Processing file 1b3JmI-ilYfgJeOs-fYPDSnZ2tWNfP7OD id6_id9_0001.mp4\n",
      "Processing file 1IZzso_CgHOkzT1jD0ZPVbKQl_pYSsH8F id6_id9_0002.mp4\n",
      "Processing file 1q_Tk6nzog4Wnx_umgrl9ZuC51BB_YrI4 id6_id9_0004.mp4\n",
      "Processing file 1-iSlcBHoUGVDG90kKiPxWiFatqpqeWDE id6_id9_0005.mp4\n",
      "Processing file 1LLjjgyJq57D2Are4e3XRBIvG5pnsRDrK id6_id9_0006.mp4\n",
      "Processing file 1OixJCSHYA5w6nkvF76FgkymG-I9LPYJK id6_id9_0007.mp4\n",
      "Processing file 13fdYc9Bu-9pjt73bwyMbG_8GngaTwSEr id6_id9_0008.mp4\n",
      "Processing file 1n_DaAkT68_fzbsLSqO8fanhH4AUpzAIG id6_id9_0009.mp4\n",
      "Processing file 1t5c1j_QxhjXXoVsPiLh69tPXllwIe4Um id6_id17_0001.mp4\n",
      "Processing file 1omcHVei8zV5Lz2TN5nbR_WbEKiE2f0Uc id6_id17_0009.mp4\n",
      "Processing file 117dGBg0zl_jiCod-1rchuPy3hAGwy8pL id6_id21_0001.mp4\n",
      "Processing file 1hIfb-yBRXcmL5ffDftqnn7PY_eNQHa-s id6_id23_0001.mp4\n",
      "Processing file 1bplFbyRmE3WefsungITpXR94eTaZe3TJ id6_id26_0005.mp4\n",
      "‚ö†Ô∏è  Download error: The gdrive folder with url: https://drive.google.com/drive/folders/18qhZEXhRWb0NmUHoYQyADJvai9sS3xTi?hl=en has more than 50 files, gdrive can't download more than this limit.\n",
      "Please download manually from:\n",
      "https://drive.google.com/drive/folders/1nBKjUpi2wQyMfWDuNsreqY11DVZrbk7x\n",
      "Extract to: data\n",
      "\n",
      "================================================================================\n",
      "MANUAL DOWNLOAD REQUIRED\n",
      "================================================================================\n",
      "Please follow these steps:\n",
      "1. Open: https://drive.google.com/drive/folders/1nBKjUpi2wQyMfWDuNsreqY11DVZrbk7x\n",
      "2. Download the three folders: Celeb-Real, Celeb-Fake, Testing\n",
      "3. Extract them to: /Users/mohini.gangaram/Desktop/MLPostGrad/Sem3/Deep Learning/Final Project/data\n",
      "4. Ensure folder structure:\n",
      "   data/Celeb-Real/\n",
      "   data/Celeb-Fake/\n",
      "   data/Testing/\n",
      "\n",
      "Then re-run this cell.\n",
      "\n",
      "================================================================================\n",
      "LOADING VIDEOS FROM FOLDERS\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Training videos loaded: 0\n",
      "‚úÖ Test videos loaded: 0\n",
      "\n",
      "‚ö†Ô∏è  No training videos found!\n",
      "Please ensure the dataset folders are downloaded and placed in the 'data/' directory.\n"
     ]
    }
   ],
   "source": [
    "# ## 2. Data Loading from Google Drive Folders\n",
    "# Dataset Structure:\n",
    "# - celeb-real/: Real videos (label: 0, \"Celeb-Real\")\n",
    "# - celeb-fake/: Fake videos (label: 1, \"Fake\")\n",
    "# - testing/: Test videos (for evaluation)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING DATASET FROM GOOGLE DRIVE FOLDERS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Install gdown for downloading from Google Drive\n",
    "%pip install gdown\n",
    "\n",
    "import gdown\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# Set up data directory - using absolute path from project root\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Data directory exists: {DATA_DIR.exists()}\")\n",
    "\n",
    "# Google Drive folder IDs (extracted from the share link)\n",
    "GOOGLE_DRIVE_FOLDER_ID = \"1nBKjUpi2wQyMfWDuNsreqY11DVZrbk7x\"\n",
    "\n",
    "# Try to find folders with case-insensitive matching\n",
    "def find_folder(base_dir, possible_names):\n",
    "    \"\"\"Find folder with case-insensitive matching\"\"\"\n",
    "    base_dir = Path(base_dir)\n",
    "    if not base_dir.exists():\n",
    "        return None\n",
    "    \n",
    "    # First try exact match\n",
    "    for name in possible_names:\n",
    "        folder = base_dir / name\n",
    "        if folder.exists() and folder.is_dir():\n",
    "            return folder\n",
    "    \n",
    "    # Then try case-insensitive match\n",
    "    for item in base_dir.iterdir():\n",
    "        if item.is_dir():\n",
    "            item_lower = item.name.lower()\n",
    "            for name in possible_names:\n",
    "                if item_lower == name.lower():\n",
    "                    return item\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Find folders with various possible names\n",
    "# Note: Actual folder names may vary (Celeb-real, Celeb-synthesis, etc.)\n",
    "CELEB_REAL_FOLDER = find_folder(DATA_DIR, [\n",
    "    \"Celeb-Real\", \"celeb-real\", \"Celeb-real\", \"Celeb_Real\", \"celeb_real\", \n",
    "    \"CelebReal\", \"Celeb-Real\", \"real\", \"Real\"\n",
    "])\n",
    "CELEB_FAKE_FOLDER = find_folder(DATA_DIR, [\n",
    "    \"Celeb-Fake\", \"celeb-fake\", \"Celeb-fake\", \"Celeb_Fake\", \"celeb_fake\", \n",
    "    \"CelebFake\", \"Celeb-synthesis\", \"celeb-synthesis\", \"Celeb-Synthesis\",\n",
    "    \"synthesis\", \"Synthesis\", \"fake\", \"Fake\"\n",
    "])\n",
    "TESTING_FOLDER = find_folder(DATA_DIR, [\"Testing\", \"testing\", \"Test\", \"test\"])\n",
    "\n",
    "def download_from_google_drive(folder_id, output_dir):\n",
    "    \"\"\"Download folder from Google Drive using gdown\"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(f\"Downloading from Google Drive folder: {folder_id}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    \n",
    "    # Download folder as zip\n",
    "    url = f\"https://drive.google.com/drive/u/0/folders/{folder_id}\"         # f\"https://drive.google.com/uc?id={folder_id}\"\n",
    "    zip_path = output_dir / \"dataset.zip\"\n",
    "    \n",
    "    try:\n",
    "        gdown.download_folder(url, output=str(output_dir), quiet=False, use_cookies=False)\n",
    "        print(f\"‚úÖ Downloaded to {output_dir}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Download error: {e}\")\n",
    "        print(\"Please download manually from:\")\n",
    "        print(f\"https://drive.google.com/drive/folders/{folder_id}\")\n",
    "        print(f\"Extract to: {output_dir}\")\n",
    "        return False\n",
    "\n",
    "def load_videos_from_folder(folder_path, label, label_name):\n",
    "    \"\"\"Load all video files from a folder\"\"\"\n",
    "    folder_path = Path(folder_path)\n",
    "    if not folder_path.exists():\n",
    "        return []\n",
    "    \n",
    "    # Supported video formats\n",
    "    video_extensions = ['*.mp4', '*.avi', '*.mov', '*.mkv', '*.flv', '*.wmv', '*.webm']\n",
    "    video_files = []\n",
    "    \n",
    "    for ext in video_extensions:\n",
    "        video_files.extend(glob.glob(str(folder_path / \"**\" / ext), recursive=True))\n",
    "    \n",
    "    # Create data entries\n",
    "    data_list = []\n",
    "    for video_path in video_files:\n",
    "        data_list.append({\n",
    "            'video_path': video_path,\n",
    "            'label': label,\n",
    "            'label_name': label_name,\n",
    "            'folder': folder_path.name\n",
    "        })\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "# Download or check for local dataset\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHECKING FOR LOCAL DATASET FOLDERS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# List all items in data directory\n",
    "if DATA_DIR.exists():\n",
    "    print(f\"\\nüìÅ Contents of data directory ({DATA_DIR}):\")\n",
    "    items = list(DATA_DIR.iterdir())\n",
    "    if items:\n",
    "        for item in sorted(items):\n",
    "            item_type = \"üìÅ\" if item.is_dir() else \"üìÑ\"\n",
    "            print(f\"   {item_type} {item.name}\")\n",
    "    else:\n",
    "        print(\"   (empty)\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Data directory does not exist: {DATA_DIR}\")\n",
    "\n",
    "print(f\"\\n[INFO] Looking for dataset folders...\")\n",
    "print(f\"Celeb-Real folder: {CELEB_REAL_FOLDER}\")\n",
    "print(f\"Celeb-Fake folder: {CELEB_FAKE_FOLDER}\")\n",
    "print(f\"Testing folder: {TESTING_FOLDER}\")\n",
    "\n",
    "# Check if folders exist locally\n",
    "if CELEB_REAL_FOLDER is None or CELEB_FAKE_FOLDER is None:\n",
    "    print(\"\\n[INFO] Dataset folders not found locally.\")\n",
    "    print(\"Attempting to download from Google Drive...\")\n",
    "    print(\"Note: If download fails, please download manually and place folders in 'data/' directory\")\n",
    "    \n",
    "    # Try to download (this might not work for large folders, manual download recommended)\n",
    "    download_success = download_from_google_drive(GOOGLE_DRIVE_FOLDER_ID, DATA_DIR)\n",
    "    \n",
    "    if not download_success:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"MANUAL DOWNLOAD REQUIRED\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"Please follow these steps:\")\n",
    "        print(f\"1. Open: https://drive.google.com/drive/folders/{GOOGLE_DRIVE_FOLDER_ID}\")\n",
    "        print(\"2. Download the three folders: Celeb-Real, Celeb-Fake, Testing\")\n",
    "        print(f\"3. Extract them to: {DATA_DIR.absolute()}\")\n",
    "        print(\"4. Ensure folder structure:\")\n",
    "        print(f\"   {DATA_DIR}/Celeb-Real/\")\n",
    "        print(f\"   {DATA_DIR}/Celeb-Fake/\")\n",
    "        print(f\"   {DATA_DIR}/Testing/\")\n",
    "        print(\"\\nThen re-run this cell.\")\n",
    "else:\n",
    "    print(\"‚úÖ Dataset folders found locally!\")\n",
    "\n",
    "# Load videos from folders\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING VIDEOS FROM FOLDERS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load training data (Celeb-Real and Celeb-Fake)\n",
    "train_data_list = []\n",
    "if CELEB_REAL_FOLDER and CELEB_REAL_FOLDER.exists():\n",
    "    real_videos = load_videos_from_folder(CELEB_REAL_FOLDER, label=0, label_name=\"Celeb-Real\")\n",
    "    train_data_list.extend(real_videos)\n",
    "    print(f\"   ‚úÖ Loaded {len(real_videos)} videos from {CELEB_REAL_FOLDER.name} folder (Label: 0, 'Celeb-Real')\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  Celeb-Real folder not found or empty\")\n",
    "    print(f\"   Expected folder names: Celeb-Real, celeb-real, Celeb-real, etc.\")\n",
    "\n",
    "if CELEB_FAKE_FOLDER and CELEB_FAKE_FOLDER.exists():\n",
    "    fake_videos = load_videos_from_folder(CELEB_FAKE_FOLDER, label=1, label_name=\"Fake\")\n",
    "    train_data_list.extend(fake_videos)\n",
    "    print(f\"   ‚úÖ Loaded {len(fake_videos)} videos from {CELEB_FAKE_FOLDER.name} folder (Label: 1, 'Fake')\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  Celeb-Fake folder not found or empty\")\n",
    "    print(f\"   Expected folder names: Celeb-Fake, Celeb-synthesis, celeb-fake, etc.\")\n",
    "\n",
    "# Load test data (Testing folder)\n",
    "if TESTING_FOLDER and TESTING_FOLDER.exists():\n",
    "    test_data_list = load_videos_from_folder(TESTING_FOLDER, label=None, label_name=\"Testing\")\n",
    "    print(f\"   Loaded {len(test_data_list)} videos from Testing folder\")\n",
    "else:\n",
    "    test_data_list = []\n",
    "    print(\"   ‚ö†Ô∏è  Testing folder not found or empty (optional for training)\")\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "train_df = pd.DataFrame(train_data_list)\n",
    "test_df = pd.DataFrame(test_data_list)\n",
    "\n",
    "print(f\"\\n‚úÖ Training videos loaded: {len(train_df)}\")\n",
    "print(f\"‚úÖ Test videos loaded: {len(test_df)}\")\n",
    "\n",
    "if len(train_df) > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LABEL DISTRIBUTION ANALYSIS (Training Data)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nTotal training samples: {len(train_df)}\")\n",
    "    print(f\"\\nLabel Distribution:\")\n",
    "    print(train_df['label_name'].value_counts())\n",
    "    print(f\"\\nLabel Percentages:\")\n",
    "    print(train_df['label_name'].value_counts(normalize=True) * 100)\n",
    "    \n",
    "    # Check if we have both classes\n",
    "    unique_labels = train_df['label'].unique()\n",
    "    print(f\"\\nUnique labels found: {unique_labels}\")\n",
    "    \n",
    "    if len(unique_labels) == 1:\n",
    "        print(\"\\n‚ö†Ô∏è  WARNING: Only one class found in the dataset!\")\n",
    "        print(f\"   All samples are labeled as: {train_df['label_name'].iloc[0]}\")\n",
    "    else:\n",
    "        print(\"\\n‚úì Both classes found in the dataset!\")\n",
    "        print(\"   The dataset contains both Celeb-Real and Fake videos.\")\n",
    "    \n",
    "    # Show sample paths\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SAMPLE PATHS (First 10):\")\n",
    "    print(\"=\"*80)\n",
    "    for idx, row in train_df.head(10).iterrows():\n",
    "        print(f\"Sample {idx}: {row['label_name']}\")\n",
    "        print(f\"  Path: {row['video_path']}\")\n",
    "    \n",
    "    # Visualize label distribution\n",
    "    if len(train_df) > 0:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Count plot\n",
    "        label_counts = train_df['label_name'].value_counts()\n",
    "        axes[0].bar(label_counts.index, label_counts.values, color=['#2ecc71', '#e74c3c'])\n",
    "        axes[0].set_title('Label Distribution (Count)', fontsize=14, fontweight='bold')\n",
    "        axes[0].set_xlabel('Label', fontsize=12)\n",
    "        axes[0].set_ylabel('Count', fontsize=12)\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Pie chart\n",
    "        colors = ['#2ecc71', '#e74c3c']\n",
    "        axes[1].pie(label_counts.values, labels=label_counts.index, autopct='%1.1f%%',\n",
    "                   colors=colors[:len(label_counts)], startangle=90)\n",
    "        axes[1].set_title('Label Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('label_distribution_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    print(f\"\\n‚úì Training dataset loaded: {len(train_df)} videos\")\n",
    "    print(f\"‚úì Test dataset loaded: {len(test_df)} videos\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No training videos found!\")\n",
    "    print(\"Please ensure the dataset folders are downloaded and placed in the 'data/' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5d824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional analysis: Check dataset structure and video files\n",
    "print(\"=\"*80)\n",
    "print(\"DATASET STRUCTURE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'train_df' in locals() and len(train_df) > 0:\n",
    "    print(f\"\\n‚úÖ Training Dataset Structure:\")\n",
    "    print(f\"   Total videos: {len(train_df)}\")\n",
    "    print(f\"   Columns: {train_df.columns.tolist()}\")\n",
    "    print(f\"\\n   Label distribution:\")\n",
    "    print(train_df['label_name'].value_counts())\n",
    "    \n",
    "    # Check video file formats\n",
    "    print(f\"\\nüìπ Video File Formats:\")\n",
    "    train_df['extension'] = train_df['video_path'].apply(lambda x: Path(x).suffix.lower())\n",
    "    print(train_df['extension'].value_counts())\n",
    "    \n",
    "    # Sample video paths by label\n",
    "    print(f\"\\nüìÅ Sample Video Paths by Label:\")\n",
    "    for label_name in train_df['label_name'].unique():\n",
    "        print(f\"\\n   {label_name} videos:\")\n",
    "        sample_paths = train_df[train_df['label_name'] == label_name]['video_path'].head(3)\n",
    "        for path in sample_paths:\n",
    "            print(f\"     - {Path(path).name}\")\n",
    "    \n",
    "    if 'test_df' in locals() and len(test_df) > 0:\n",
    "        print(f\"\\n‚úÖ Test Dataset Structure:\")\n",
    "        print(f\"   Total test videos: {len(test_df)}\")\n",
    "        print(f\"   Test videos are in: {TESTING_FOLDER}\")\n",
    "    \n",
    "    print(f\"\\nüìä Dataset Summary:\")\n",
    "    print(f\"   Training: {len(train_df)} videos\")\n",
    "    print(f\"   Testing: {len(test_df) if 'test_df' in locals() else 0} videos\")\n",
    "    print(f\"   Total: {len(train_df) + (len(test_df) if 'test_df' in locals() else 0)} videos\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Dataset not loaded. Please run the previous cell first.\")\n",
    "    print(\"Make sure the dataset folders are downloaded and placed in the 'data/' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c12ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract frame from video file\n",
    "def extract_frame_from_video(video_path, frame_idx=0):\n",
    "    \"\"\"Extract a frame from video file path\"\"\"\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(str(video_path))\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video {video_path}\")\n",
    "            return None\n",
    "        \n",
    "        # Get total frames\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # Set frame position\n",
    "        if frame_idx >= total_frames:\n",
    "            frame_idx = total_frames - 1\n",
    "        \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        cap.release()\n",
    "        \n",
    "        if ret:\n",
    "            # Convert BGR to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            return frame_rgb\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting frame from {video_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test video loading\n",
    "if 'train_df' in locals() and len(train_df) > 0:\n",
    "    print(\"Testing video frame extraction...\")\n",
    "    sample_video = train_df.iloc[0]['video_path']\n",
    "    print(f\"Sample video: {sample_video}\")\n",
    "    \n",
    "    frame = extract_frame_from_video(sample_video, frame_idx=0)\n",
    "    if frame is not None:\n",
    "        print(f\"‚úÖ Frame extracted successfully!\")\n",
    "        print(f\"   Frame shape: {frame.shape}\")\n",
    "        \n",
    "        # Display sample frame\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(frame)\n",
    "        plt.title(f\"Sample Frame from: {Path(sample_video).name}\\nLabel: {train_df.iloc[0]['label_name']}\")\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('sample_video_frame.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Could not extract frame. Check video file format.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No training data available. Please load dataset first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f9e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset Class for Video Loading\n",
    "class VideoDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for loading videos from local folders.\n",
    "    Labels are assigned based on folder location:\n",
    "    - Celeb-Real folder ‚Üí Label 0 (\"Celeb-Real\")\n",
    "    - Celeb-Fake folder ‚Üí Label 1 (\"Fake\")\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, transform=None, num_frames=16, frame_interval=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe: DataFrame with columns ['video_path', 'label', 'label_name', 'folder']\n",
    "            transform: Optional transform to be applied on frames\n",
    "            num_frames: Number of frames to extract from each video\n",
    "            frame_interval: Interval between frames (1 = consecutive frames)\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.num_frames = num_frames\n",
    "        self.frame_interval = frame_interval\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.dataframe.iloc[idx]['video_path']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "        label_name = self.dataframe.iloc[idx]['label_name']\n",
    "        folder = self.dataframe.iloc[idx]['folder']\n",
    "        \n",
    "        # Extract frames from video\n",
    "        frames = self.extract_frames(video_path)\n",
    "        \n",
    "        # Apply transforms if provided\n",
    "        if self.transform:\n",
    "            frames = [self.transform(frame) for frame in frames]\n",
    "        \n",
    "        # Convert list of frames to tensor\n",
    "        # Stack frames: [num_frames, C, H, W]\n",
    "        frames_tensor = torch.stack(frames)\n",
    "        \n",
    "        return {\n",
    "            'frames': frames_tensor,\n",
    "            'label': torch.tensor(label, dtype=torch.long),\n",
    "            'label_name': label_name,\n",
    "            'folder': folder,\n",
    "            'video_path': video_path\n",
    "        }\n",
    "    \n",
    "    def extract_frames(self, video_path):\n",
    "        \"\"\"Extract frames from video file\"\"\"\n",
    "        cap = cv2.VideoCapture(str(video_path))\n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(f\"Could not open video: {video_path}\")\n",
    "        \n",
    "        frames = []\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        # Calculate frame indices to extract\n",
    "        if total_frames < self.num_frames * self.frame_interval:\n",
    "            # If video is shorter, extract all frames and pad\n",
    "            frame_indices = list(range(0, total_frames, self.frame_interval))\n",
    "        else:\n",
    "            # Extract evenly spaced frames\n",
    "            step = max(1, total_frames // (self.num_frames * self.frame_interval))\n",
    "            frame_indices = [i * step for i in range(self.num_frames)]\n",
    "        \n",
    "        for frame_idx in frame_indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                # Convert BGR to RGB\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                # Convert to PIL Image for transforms\n",
    "                frame_pil = Image.fromarray(frame_rgb)\n",
    "                frames.append(frame_pil)\n",
    "            else:\n",
    "                # If frame read fails, use last successful frame\n",
    "                if frames:\n",
    "                    frames.append(frames[-1])\n",
    "                else:\n",
    "                    # Create black frame as fallback\n",
    "                    frame_pil = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "                    frames.append(frame_pil)\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        # Pad or trim to exact number of frames\n",
    "        while len(frames) < self.num_frames:\n",
    "            frames.append(frames[-1] if frames else Image.new('RGB', (224, 224), (0, 0, 0)))\n",
    "        \n",
    "        frames = frames[:self.num_frames]\n",
    "        \n",
    "        return frames\n",
    "\n",
    "# Define transforms for training and validation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets if training data is available\n",
    "if 'train_df' in locals() and len(train_df) > 0:\n",
    "    print(\"Creating PyTorch datasets...\")\n",
    "    \n",
    "    # Split training data into train and validation sets\n",
    "    train_split_df, val_split_df = train_test_split(\n",
    "        train_df, \n",
    "        test_size=0.2, \n",
    "        random_state=SEED, \n",
    "        stratify=train_df['label']\n",
    "    )\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = VideoDataset(train_split_df, transform=train_transform, num_frames=16)\n",
    "    val_dataset = VideoDataset(val_split_df, transform=val_transform, num_frames=16)\n",
    "    \n",
    "    # Create test dataset if available\n",
    "    if 'test_df' in locals() and len(test_df) > 0:\n",
    "        test_dataset = VideoDataset(test_df, transform=val_transform, num_frames=16)\n",
    "        print(f\"‚úÖ Test dataset created: {len(test_dataset)} videos\")\n",
    "    else:\n",
    "        test_dataset = None\n",
    "        print(\"‚ö†Ô∏è  No test dataset available\")\n",
    "    \n",
    "    print(f\"‚úÖ Training dataset: {len(train_dataset)} videos\")\n",
    "    print(f\"‚úÖ Validation dataset: {len(val_dataset)} videos\")\n",
    "    print(f\"\\nDataset splits:\")\n",
    "    print(f\"  Train: {len(train_split_df)} videos\")\n",
    "    print(f\"  Validation: {len(val_split_df)} videos\")\n",
    "    print(f\"  Test: {len(test_df) if 'test_df' in locals() else 0} videos\")\n",
    "    \n",
    "    # Test dataset loading\n",
    "    print(\"\\nTesting dataset loading...\")\n",
    "    sample = train_dataset[0]\n",
    "    print(f\"‚úÖ Sample loaded successfully!\")\n",
    "    print(f\"   Frames shape: {sample['frames'].shape}\")\n",
    "    print(f\"   Label: {sample['label'].item()} ({sample['label_name']})\")\n",
    "    print(f\"   Folder: {sample['folder']}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No training data available. Please load dataset first (run Cell 2).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake_env (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
